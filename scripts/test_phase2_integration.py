#!/usr/bin/env python3
# Legal Chatbot - Phase 2 Integration Tests
# Test all Phase 2 features without model loading (to avoid PyTorch multiprocessing issues)

import os
import sys
from pathlib import Path
import logging

# Add project root to Python path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_imports():
    """Test all Phase 2 imports"""
    print("=" * 60)
    print("1Ô∏è‚É£ Testing Phase 2 Imports")
    print("=" * 60)
    
    try:
        from retrieval.bm25_retriever import BM25Retriever
        print("‚úÖ BM25Retriever imported")
    except Exception as e:
        print(f"‚ùå BM25Retriever import failed: {e}")
        return False
    
    try:
        from retrieval.semantic_retriever import SemanticRetriever
        print("‚úÖ SemanticRetriever imported")
    except Exception as e:
        print(f"‚ùå SemanticRetriever import failed: {e}")
        return False
    
    try:
        from retrieval.hybrid_retriever import AdvancedHybridRetriever, FusionStrategy
        print("‚úÖ AdvancedHybridRetriever imported")
        print(f"   FusionStrategy.RRF: {FusionStrategy.RRF}")
        print(f"   FusionStrategy.WEIGHTED: {FusionStrategy.WEIGHTED}")
    except Exception as e:
        print(f"‚ùå AdvancedHybridRetriever import failed: {e}")
        return False
    
    try:
        from retrieval.metadata_filter import MetadataFilter, FilterOperator
        print("‚úÖ MetadataFilter imported")
    except Exception as e:
        print(f"‚ùå MetadataFilter import failed: {e}")
        return False
    
    try:
        from retrieval.rerankers.cross_encoder_reranker import CrossEncoderReranker
        print("‚úÖ CrossEncoderReranker imported")
    except Exception as e:
        print(f"‚ùå CrossEncoderReranker import failed: {e}")
        return False
    
    try:
        from retrieval.explainability import ExplainabilityAnalyzer, RetrievalExplanation
        print("‚úÖ ExplainabilityAnalyzer imported")
    except Exception as e:
        print(f"‚ùå ExplainabilityAnalyzer import failed: {e}")
        return False
    
    try:
        from retrieval.red_team_tester import RedTeamTester, RedTeamTestResult
        print("‚úÖ RedTeamTester imported")
    except Exception as e:
        print(f"‚ùå RedTeamTester import failed: {e}")
        return False
    
    try:
        from app.services.rag_service import RAGService
        print("‚úÖ RAGService imported")
    except Exception as e:
        print(f"‚ùå RAGService import failed: {e}")
        return False
    
    try:
        from app.models.schemas import HybridSearchRequest, HybridSearchResult, FusionStrategy
        print("‚úÖ API schemas imported")
    except Exception as e:
        print(f"‚ùå API schemas import failed: {e}")
        return False
    
    return True


def test_bm25_retriever():
    """Test BM25 retriever functionality"""
    print("\n" + "=" * 60)
    print("2Ô∏è‚É£ Testing BM25 Retriever")
    print("=" * 60)
    
    try:
        from retrieval.bm25_retriever import BM25Retriever
        
        documents = [
            "A contract of sale includes implied conditions about quality.",
            "Employment law covers employee rights and obligations.",
            "Contract law is fundamental to legal transactions.",
            "The Sale of Goods Act 1979 sets out legal requirements."
        ]
        
        retriever = BM25Retriever(documents)
        results = retriever.search("contract law", top_k=2)
        
        print(f"‚úÖ BM25 retriever initialized with {len(documents)} documents")
        print(f"‚úÖ Search returned {len(results)} results")
        
        if results:
            for i, (idx, score) in enumerate(results, 1):
                print(f"   {i}. Doc {idx}: Score {score:.3f}")
        
        return True
    except Exception as e:
        print(f"‚ùå BM25 retriever test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_metadata_filter():
    """Test metadata filtering"""
    print("\n" + "=" * 60)
    print("3Ô∏è‚É£ Testing Metadata Filtering")
    print("=" * 60)
    
    try:
        from retrieval.metadata_filter import MetadataFilter
        
        # Test empty filter
        empty_filter = MetadataFilter()
        assert empty_filter.is_empty(), "Empty filter should be empty"
        print("‚úÖ Empty filter check passed")
        
        # Test equals filter
        filter_obj = MetadataFilter()
        filter_obj.add_equals_filter("jurisdiction", "UK")
        assert not filter_obj.is_empty(), "Filter with condition should not be empty"
        print("‚úÖ Equals filter added")
        
        # Test IN filter
        filter_obj.add_in_filter("document_type", ["statute", "contract"])
        print(f"‚úÖ IN filter added (total conditions: {len(filter_obj.filters)})")
        
        # Test chunk filtering
        chunks = [
            {"metadata": {"jurisdiction": "UK", "document_type": "statute"}},
            {"metadata": {"jurisdiction": "US", "document_type": "statute"}},
            {"metadata": {"jurisdiction": "UK", "document_type": "contract"}},
        ]
        
        filtered = filter_obj.filter_chunks(chunks)
        print(f"‚úÖ Filtered {len(chunks)} chunks to {len(filtered)} chunks")
        
        return True
    except Exception as e:
        print(f"‚ùå Metadata filter test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_explainability():
    """Test explainability features"""
    print("\n" + "=" * 60)
    print("4Ô∏è‚É£ Testing Explainability")
    print("=" * 60)
    
    try:
        from retrieval.explainability import ExplainabilityAnalyzer
        
        analyzer = ExplainabilityAnalyzer()
        query = "What are employee rights in the UK?"
        text = "Employees in the UK have various rights under employment law."
        
        # Test term extraction
        terms = analyzer.extract_query_terms(query)
        print(f"‚úÖ Query terms extracted: {terms}")
        
        # Test highlighting
        highlighted, spans = analyzer.highlight_matched_terms(text, query)
        print(f"‚úÖ Text highlighted: {highlighted[:60]}...")
        print(f"‚úÖ Matched spans: {spans}")
        
        # Test explanation
        result = {
            "chunk_id": "chunk_1",
            "text": text,
            "similarity_score": 0.85,
            "bm25_score": 0.75,
            "semantic_score": 0.90,
            "bm25_rank": 2,
            "semantic_rank": 1,
            "rank": 1
        }
        
        explanation = analyzer.explain_retrieval(result, query)
        print(f"‚úÖ Explanation generated: {explanation.explanation[:80]}...")
        print(f"‚úÖ Confidence: {explanation.confidence:.3f}")
        
        return True
    except Exception as e:
        print(f"‚ùå Explainability test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_red_team_tester():
    """Test red team tester"""
    print("\n" + "=" * 60)
    print("5Ô∏è‚É£ Testing Red Team Tester")
    print("=" * 60)
    
    try:
        from retrieval.red_team_tester import RedTeamTester
        
        tester = RedTeamTester()
        test_cases = tester.load_test_cases()
        
        print(f"‚úÖ RedTeamTester initialized")
        print(f"‚úÖ Loaded {len(test_cases)} test cases")
        
        # Show categories
        categories = {}
        for tc in test_cases:
            cat = tc.get('category', 'unknown')
            categories[cat] = categories.get(cat, 0) + 1
        
        print(f"‚úÖ Test categories: {', '.join(categories.keys())}")
        
        # Test single test case execution (without guardrails)
        if test_cases:
            test_case = test_cases[0]
            result = tester.run_test_case(test_case, use_rag=False)
            print(f"‚úÖ Test case execution: {result.test_id} - {result.actual_behavior}")
        
        return True
    except Exception as e:
        print(f"‚ùå Red team tester test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_api_schemas():
    """Test API schemas"""
    print("\n" + "=" * 60)
    print("6Ô∏è‚É£ Testing API Schemas")
    print("=" * 60)
    
    try:
        from app.models.schemas import (
            HybridSearchRequest, HybridSearchResult, FusionStrategy,
            MetadataFilterRequest
        )
        
        # Test request schema
        request = HybridSearchRequest(
            query="What is contract law?",
            top_k=5,
            fusion_strategy=FusionStrategy.RRF,
            include_explanation=True,
            highlight_sources=True,
            metadata_filters=[
                MetadataFilterRequest(field="jurisdiction", value="UK", operator="eq")
            ]
        )
        
        print(f"‚úÖ HybridSearchRequest created")
        print(f"   Query: {request.query}")
        print(f"   Fusion strategy: {request.fusion_strategy.value}")
        print(f"   Include explanation: {request.include_explanation}")
        print(f"   Highlight sources: {request.highlight_sources}")
        
        # Test result schema
        result = HybridSearchResult(
            chunk_id="chunk_1",
            text="Test text",
            similarity_score=0.85,
            bm25_score=0.75,
            semantic_score=0.90,
            rank=1,
            section="Test Section",
            explanation="Test explanation",
            confidence=0.85,
            matched_terms=["contract", "law"],
            highlighted_text="Test **text**"
        )
        
        print(f"‚úÖ HybridSearchResult created with explainability fields")
        
        return True
    except Exception as e:
        print(f"‚ùå API schemas test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_configuration():
    """Test configuration"""
    print("\n" + "=" * 60)
    print("7Ô∏è‚É£ Testing Configuration")
    print("=" * 60)
    
    try:
        from app.core.config import settings
        
        print(f"‚úÖ Configuration loaded")
        print(f"   EMBEDDING_MODEL: {settings.EMBEDDING_MODEL}")
        print(f"   ENABLE_RERANKING: {settings.ENABLE_RERANKING}")
        print(f"   RERANKER_MODEL: {settings.RERANKER_MODEL}")
        print(f"   HYBRID_SEARCH_FUSION_STRATEGY: {settings.HYBRID_SEARCH_FUSION_STRATEGY}")
        print(f"   HYBRID_SEARCH_BM25_WEIGHT: {settings.HYBRID_SEARCH_BM25_WEIGHT}")
        print(f"   HYBRID_SEARCH_SEMANTIC_WEIGHT: {settings.HYBRID_SEARCH_SEMANTIC_WEIGHT}")
        
        return True
    except Exception as e:
        print(f"‚ùå Configuration test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    print("üß™ Phase 2 Integration Test Suite")
    print("=" * 60)
    print("Testing all Phase 2 features (without model loading)")
    print("=" * 60)
    
    results = []
    
    # Run all tests
    results.append(("Imports", test_imports()))
    results.append(("BM25 Retriever", test_bm25_retriever()))
    results.append(("Metadata Filter", test_metadata_filter()))
    results.append(("Explainability", test_explainability()))
    results.append(("Red Team Tester", test_red_team_tester()))
    results.append(("API Schemas", test_api_schemas()))
    results.append(("Configuration", test_configuration()))
    
    # Summary
    print("\n" + "=" * 60)
    print("üìä Test Summary")
    print("=" * 60)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for name, result in results:
        status = "‚úÖ PASS" if result else "‚ùå FAIL"
        print(f"   {name:<25}: {status}")
    
    print(f"\n   Total: {passed}/{total} tests passed ({passed/total*100:.1f}%)")
    
    if passed == total:
        print("\n‚úÖ All Phase 2 integration tests passed!")
        sys.exit(0)
    else:
        print(f"\n‚ö†Ô∏è {total - passed} test(s) failed")
        sys.exit(1)

